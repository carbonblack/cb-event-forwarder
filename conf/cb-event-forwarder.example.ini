###########
#General Config Options
##########

# port for HTTP diagnostics
http_server_port: 33706

event_fowarders:
    # Configure individual event forwarders below using - 
    -   ###
        ##enables data compression (gzip)
        #
        compress_data: false

        #
        # How many process pools should the script spin up to
        # process events off of the bus.
        message_processor_count: 4

        #
        # This is a name that gets populated in all JSON objects
        # as "cb_server".  This can help distinguish messages when
        # data from multiple Cb Response deployments are merged
        # into a single source
        server_name: cbserver

        #
        # enables extra debugging output and stores zip bundles if errors occur during processing
        #
        #debug: 0
        #debug_store: /tmp

        #
        #Control Audit logging
        #
        #audit_log: false

        #
        # Bus Connection Options
        #
        # There are two deployment options:
        #
        # 1) For small deployments, or for low volume subscriptions (such as new binaries, feed/watchlist hits),
        #    you can install this connector directly on the Cb Response server. In this case, leave the following
        #    three configuration options blank and the service will connect to the local RabbitMQ instance using
        #    the credentials from the /etc/cb/cb.conf file.
        #
        # 2) For larger deployments, or for high volume subscriptions (such as raw endpoint events), it is recommended
        #    to install this connector on its own dedicated machine. In this case, fill the following three configuration
        #    options with the RabbitMQUser, RabbitMQPassword, and the IP/hostname of the Cb Response server or master
        #    node respectively. You will have to ensure that your host can connect to TCP port 5004 on the Cb Response
        #    server.
        #
        rabbit_mq_username:
        rabbit_mq_password:
        cb_server_hostname:

        # Rabbit MQ Acking
        # RabbitMQ has two options for acking events off of the message bus, automatic and manual.
        # In automatic acknowledgement mode, a message is considered to be successfully delivered
        # immediately after it is sent. This mode trades off higher throughput (as long as the consumers can keep up)
        # for reduced safety of delivery and consumer processing. With manual acking, the
        # consumer must ack each individual event sent by the producer and an event will not
        # be considered sucessfully received until the consumer sends an ack to the producer.
        # See https://www.rabbitmq.com/confirms.html for a more detailed explination.
        # Automatic acking is recommended as not all environments can keep up with the rate of acking
        # that is required. If manual acking is desired, please be sure to make sure that your
        # consumers can keep up with the number of acks necessary. This can be done by increasing
        # message_processor_count, using EnableRawSensorDataBroadcast vs events_raw_sensor,
        # and using rabbit_mq_queue_name while running multiple instances of the Event Forwarder.
        # If rabbit_mq_automatic_acking is set to true then automatic mode is used, if
        # rabbit_mq_automatic_acking is false then manual mode will be used. The default is true.
        #
        rabbit_mq_automatic_acking: true


        # Rabbit MQ queue Name
        # The RabbitMQ queue name is the name of the queue that is created on the RabbitMQ server
        # from which the event forwarder will receive events. By default this name is made up of a static
        # string, the hostname of the machine it's running on, and the pid of the event forwarder process.
        # This might not be desired in high throughput environments where it's necessary to run multiple instances
        # of the event forwarder in order to keep up with the volume of events coming off of the RabbitMQ event bus.
        # By setting rabbit_mq_queue_name to a static string the queue name will be the same across all running
        # instances of the event forwarder, allowing multiple instances of the event forwarder to consume from the
        # same RabbitMQ queue. The default is an empty string.
        #
        rabbit_mq_queue_name:

        #
        # The cb-event-forwarder can optionally place deep links into the JSON or LEEF output so users can have
        # one-click access to process, binary, or sensor context. For example, a watchlist process hit will now include:
        #  .docs[0].link_sensor: https://cbtests/#/host/7
        #  .docs[0].link_process: https://cbtests/#analyze/00000007-0000-0fd4-01d1-209aa22a57ee/1
        #  .docs[0].link_parent: https://cbtests/#analyze/00000007-0000-0fc8-01d1-209aa208f788/1
        #  .docs[0].link_process_md5: https://cbtests/#/binary/445C3E95C8CB05403AEDAEC3BAAA3A1D
        #
        # Raw endpoint events will include a "link_process", and binary watchlist hits will include a "link_md5"
        #
        # To enable these links, uncomment and place the base URL of your Cb Response server into the cb_server_url variable
        # below.

        # The cb_server_url is also used for any post processing that requires the Cb Response Server's REST API access.
        #
        # cb_server_url: https://my.company.cb.server

        #
        # Post Processing Options
        #
        # Supported post processing:
        #
        # 1) report_title in feed hits
        #
        # Post processing requires cb_server_url, api_verify_ssl, and api_token to be set.  The post processed messages are
        # dispatched to retrieve additional information from the Cb Response REST API.  Once the information is retrieved they
        # are placed in the ouput queue.
        #
        # SSL/TLS verification for connections to the Cb Response REST API
        #
        # api_verify_ssl: false
        #
        # The API Token to use when querying the Cb Response REST API
        #
        # api_token:

        #
        # add_to_output: some_metadata: value1,other_metadata: other_value
        #
        # comma separated list of key: value pairs to add to LEEF/JSON output
        add_to_output:

        #
        #remove_from_output: highlights_by_doc,stuff
        #
        #
        #comma delimited keys will be removed from LEEF/JSON output
        #
        remove_from_output:


        #########
        # Output Options
        #########

        #
        # Configure the specific output.
        # Valid options are: 'udp', 'tcp', 'file', 'stdout', 's3' ,'http','splunk',and 'kafka'
        #
        #  udp - Have the events sent over a UDP socket
        #  tcp - Have the events sent over a TCP socket
        #  file - Output the events to a rotating file
        #  s3 - Place in S3 bucket (not officially supported)
        #  syslog - Send the events to a syslog server
        #
        output_type: file

        # Configure the output format
        # valid options are: 'leef', 'json'
        #
        # default is 'json'
        # Use 'leef' for pushing events to IBM QRadar, 'json' otherwise
        #
        output_format: json

        #
        # Output specific configuration
        # These only have meaning if the option
        # is enabled
        #

        # default to /var/cb/data/event_bridge_output.json
        outfile: /var/cb/data/event_bridge_output.json

        # tcpout: IP:port - ie 1.2.3.5:8080
        tcpout:

        # udpout: IP:port - ie 1.2.3.5:8080
        udpout:

        # options for S3 support
        # s3out: can be an S3 bucket name (defaults to us-east-1 region)
        #        or (temp-file-directory):(region):(bucket-name)
        #        by default, the temp-file-directory is /var/cb/data/event-forwarder.
        #
        # for more s3 options, see the [s3] section below.
        s3out:

        # options for syslog output
        # syslogout:
        #   uses the format <protocol>:<hostname>:<port>
        #   where <protocol> can be:
        #      tcp+tls:      TCP over TLS/SSL
        #      tcp:          plaintext TCP
        #      udp:          plaintext UDP

        # example:
        #   tcp+tls:syslog.company.com:514
        syslogout:

        # options for HTTP output
        # httpout:
        #   uses the format <temporary file location>:<HTTP URL>
        #   where the temporary file location is optional; defaults to /var/cb/data/event-forwarder
        #
        # for more http options, see the [http] section below.
        #
        # examples:
        #   httpout: /tmp/http_out:https://http-endpoint.company.local/api/submit
        #   httpout: https://http-endpoint.company.local/api/submit
        httpout:

        # options for splunk output
        # splunkout:
        #   uses the format <temporary file location>:<splunk URL HEC interface URL:port>
        #   where the temporary file location is optional; defaults to /var/cb/data/event-forwarder
        #
        # for more http options, see the [splunk] section below.
        #
        # examples:
        #   splunkpout: https://<splunk-server hostname or ip>:8088/services/collector/event
        splunkout:
        #########
        # Configuration for which events are captured
        #
        # To specify multiple events use comma as a separator
        # e.g. events_raw_sensor: ingress.event.process,ingress.event.procstart
        #
        #
        # For more info on supported event types see
        # https://github.com/carbonblack/cbapi/tree/master/server_apis
        #
        # Note: To enable raw sensor events you must also edit the Cb Response config
        #  file (cb.conf) and enable the appropriate events by changing the config
        #  option DatastoreBroadcastEventTypes.
        #
        # If you intend to enable raw sensor events on a Cb Enterprise Response 5.2+ server,
        #  consider using the "raw sensor exchange" for enhanced performance and reduced
        #  load on the Cb server. The raw exchange forwards the compressed data received
        #  from the endpoint sensor unchanged to the event-forwarder. The raw sensor
        #  exchange should be used if you are forwarding moduleload, filemod, or regmod
        #  endpoint events as these represent the vast majority of the event types.
        #
        # To use the "raw sensor exchange", first uncomment the "use_raw_sensor_exchange"
        #  option below:
        #use_raw_sensor_exchange=true
        #
        #  then enable the "raw sensor exchange" in cb.conf:
        #  EnableRawSensorDataBroadcast=true
        #
        # Note: To enable binaryinfo. events you need to enable EnableSolrBinaryInfoNotifications=True
        #  within the cb.conf
        #########

        # Raw Sensor (endpoint) Events
        # Includes:
        #   ingress.event.process
        #   ingress.event.procstart
        #   ingress.event.netconn
        #   ingress.event.procend
        #   ingress.event.childproc
        #   ingress.event.moduleload
        #   ingress.event.module
        #   ingress.event.filemod
        #   ingress.event.regmod
        #   ingress.event.tamper
        #   ingress.event.crossprocopen
        #   ingress.event.remotethread
        #   ingress.event.processblock
        #   ingress.event.emetmitigation
        #   ALL for all of the above
        #   0 - to disable all raw sensor events.
        events_raw_sensor: 0

        # Watchlist Hits
        # Includes:
        #  watchlist.hit.process
        #  watchlist.hit.binary
        #  watchlist.storage.hit.process
        #  watchlist.storage.hit.binary
        # Note: As of version 5.2, the routing keys are different in RabbitMQ
        # if you want to only subscribe to watchlist.storage.hit.process (for example),
        # your configuration should be
        # events_watchlist=watchlist.*.storage.hit.process note the '*' after the '.'
        # Internally all watchlists show up with their database ID
        # ex: watchlist.12.storage.hit.process, you'll miss them without the '*'
        # (asterisk)
        events_watchlist: ALL

        # Feed Hits
        # Includes:
        #   feed.ingress.hit.process
        #   feed.ingress.hit.binary
        #   feed.ingress.hit.host
        #   feed.storage.hit.process
        #   feed.storage.hit.binary
        #   feed.query.hit.process
        #   feed.query.hit.binary
        #   ALL for all of the above
        #   0 - to disable all raw sensor events
        # Note: As of version 5.2, the routing keys are different in RabbitMQ
        # if you want to only subscribe to feed.storage.hit.process (for example), your
        # configuration should be
        # events_feed=feed.*.storage.hit.process note the '*' after the '.'
        # Internally all feeds show up with their database ID
        # ex: feed.12.storage.hit.process, you'll miss them without the '*' (asterisk)
        events_feed: ALL

        # Alert Events
        # Includes:
        #   alert.watchlist.hit.ingress.process
        #   alert.watchlist.hit.ingress.binary
        #   alert.watchlist.hit.ingress.host
        #   alert.watchlist.hit.query.process
        #   alert.watchlist.hit.query.binary
        #   ALL for all of the above
        #   0 - to disable all alert events
        events_alert: ALL

        # Binary Observed Events
        # Includes:
        #   binaryinfo.observed
        #   binaryinfo.host.observed
        #   binaryinfo.group.observed
        events_binary_observed: ALL

        # Binary Upload Events
        # Includes:
        #   binarystore.file.added
        events_binary_upload: ALL

        # Time partitioning events
        # Includes:
        #   events.partition.creating
        #   events.partition.created
        #   events.partition.mounted
        #   events.partition.unmounted
        #   events.partition.purged
        #   events.partition.deleted
        #   ALL for all of the above
        #   0 - to disable all storage partitioning events
        events_storage_partition: 0

        #########
        # S3 configuration section
        #
        # The following are advanced configuration options for uploading output to Amazon S3 buckets.
        #########

        s3:
        # By default the S3 output type will initiate a connection to the remote service every five minutes, or when
        #  the temporary file containing the event output reaches 10MB.

        # Set the default timeout period in seconds. By default, cb-event-forwarder will contact the remote service every five
        #  minutes (300 seconds)
        # bundle_send_timeout=300

        # Send empty updates? By default, cb-event-forwarder will send an empty update every bundle_send_timeout seconds.
        #  if this is set to false, then the cb-event-forwarder will not initiate a connection to the remote service unless
        #  there are events to send.
        # upload_empty_files=true

        # Set the maximum file size before the events must be flushed to the remote service. The default is 10MB.
        # bundle_size_max=10485760

        # Uncomment server_side_encryption below to enable SSE on uploaded files to your S3 bucket
        # server_side_encryption=AES256

        # Set the following ACL policy on all files uploaded to your S3 bucket
        # acl_policy=bucket-owner-full-control

        # Use the following credential profile to connect to S3.
        # See http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html for more information on
        # AWS credential storage and credential profiles. By default, the S3 output will use the default
        # credential storage location of $HOME/.aws/credentials with the "default" credential profile.
        #
        # The credential_profile can be specified as the profile name, using the default storage location, or
        # you can also specify the filename where the credentials are stored by using a colon separated format:
        # for example, to look for the AWS credentials in the file /etc/cb/aws.creds, and use profile "production":
        # set credential_profile to /etc/cb/aws.creds:production.

        # credential_profile=default

        # Use the following to create event forwarder logs under a specified object prefix
        # If specified logs will be stored under <bucketname>/<object_prefix>/event-forwarder.<timestamp>
        # This is useful if multiple forwarders are to use the same s3 bucket
        # object_prefix=objectname

        syslog:
        # Uncomment ca_cert to specify a file containing PEM-encoded CA certificates for verifying the peer
        # server when using TLS+TCP syslog
        # ca_cert=/etc/cb/integrations/event-forwarder/ca-certs.pem

        # Uncomment server_cname to force a specific server Common Name when validating the peer server
        # certificate. Useful for situations where the peer server is using a self-signed certificate with
        # a generic name (for example, QRadar's default certificate uses "*" as the CN)
        # server_cname=peer.server.name

        # Uncomment tls_verify and set to "false" in order to disable verification of the peer server certificate
        # when using TLS+TCP syslog
        # tls_verify=false

        # Uncomment insecure_tls to allow connections to servers that only support TLS versions less than 1.2.
        # The default is to only support TLSv1.2 cipher suites. This option will allow connections to TLSv1.0 and 1.1
        # servers as well.
        # insecure_tls=true

        # Uncomment client_key and client_cert and set to files containing PEM-encoded private key and public
        # certificate when using client TLS certificates when using TLS+TCP syslog
        # client_key=/etc/cb/integrations/event-forwarder/client-key.pem
        # client_cert=/etc/cb/integrations/event-forwarder/client-cert.pem

        http:
        # By default the HTTP POST output type will initiate a connection to the remote service every five minutes, or when
        #  the temporary file containing the event output reaches 10MB.

        # Set the default timeout period in seconds. By default, cb-event-forwarder will contact the remote service every five
        #  minutes (300 seconds)
        # bundle_send_timeout=300

        # Send empty updates? By default, cb-event-forwarder will send an empty update every bundle_send_timeout seconds.
        #  if this is set to false, then the cb-event-forwarder will not initiate a connection to the remote service unless
        #  there are events to send.
        # upload_empty_files=true

        # Set the maximum file size before the events must be flushed to the remote service. The default is 10MB.
        # bundle_size_max=10485760

        # Override the default template used for posting JSON to the remote service.
        # The template language is Go's text/template; see https://golang.org/pkg/text/template/
        # The following placeholders can be used:
        #  {{.FileName}} - the filename of the current event-forwarder file being uploaded (for example event-forwarder.2016-08-11T01:01:01Z)
        #  {{.Events}} - the list of events being uploaded as a "range". Each event has the following placeholder:
        #   {{.EventText}} - the event itself, as a JSON dictionary.
        #                    Note that a comma is added to each event (except the last) to make the list proper JSON.
        # The default template for JSON is:
        # http_post_template={"filename": "{{.FileName}}", "service": "carbonblack", "alerts":[{{range .Events}}{{.EventText}}{{end}}]}

        # Override the content-type sent to the remote service through the HTTP Content-Type header.
        #  The default content-type for JSON output is application/json.
        # content_type=application/json

        # Uncomment ca_cert to specify a file containing PEM-encoded CA certificates for verifying the peer server
        # ca_cert=/etc/cb/integrations/event-forwarder/ca-certs.pem

        # Uncomment server_cname to force a specific server Common Name when validating the peer server
        # certificate. Useful for situations where the peer server is using a self-signed certificate with
        # a generic name (for example, QRadar's default certificate uses "*" as the CN)
        # server_cname=peer.server.name

        # Uncomment tls_verify and set to "false" in order to disable verification of the peer server certificate
        # tls_verify=false

        # Uncomment insecure_tls to allow connections to servers that only support TLS versions less than 1.2.
        # The default is to only support TLSv1.2 cipher suites. This option will allow connections to TLSv1.0 and 1.1
        # servers as well.
        # insecure_tls=true

        # Uncomment client_key and client_cert and set to files containing PEM-encoded private key and public
        #  certificate when using client TLS certificates
        # client_key=/etc/cb/integrations/event-forwarder/client-key.pem
        # client_cert=/etc/cb/integrations/event-forwarder/client-cert.pem

        # Uncomment authorization_token to place a value in the outgoing HTTP "Authorization" header
        #  (used in HTTP Basic Authentication). See https://en.wikipedia.org/wiki/Basic_access_authentication
        #  for more information. By default no Authorization header is sent.
        # authorization_token=Basic QWxhZGRpbjpPcGVuU2VzYW1l

        splunk:
        # Uncomment ca_cert to specify a file containing PEM-encoded CA certificates for verifying the peer server
        # ca_cert=/etc/cb/integrations/event-forwarder/ca-certs.pem

        # Uncomment server_cname to force a specific server Common Name when validating the peer server
        # certificate. Useful for situations where the peer server is using a self-signed certificate with
        # a generic name (for example, QRadar's default certificate uses "*" as the CN)
        # server_cname=peer.server.name

        # Uncomment tls_verify and set to "false" in order to disable verification of the peer server certificate
        # tls_verify=false

        # Uncomment insecure_tls to allow connections to servers that only support TLS versions less than 1.2.
        # The default is to only support TLSv1.2 cipher suites. This option will allow connections to TLSv1.0 and 1.1
        # servers as well.
        # insecure_tls=true

        # Uncomment client_key and client_cert and set to files containing PEM-encoded private key and public
        #  certificate when using client TLS certificates
        # client_key=/etc/cb/integrations/event-forwarder/client-key.pem
        # client_cert=/etc/cb/integrations/event-forwarder/client-cert.pem

        # Set the default timeout period in seconds. By default, cb-event-forwarder will contact the remote service every five
        #  minutes (300 seconds)
        # bundle_send_timeout=300

        # Send empty updates? By default, cb-event-forwarder will send an empty update every bundle_send_timeout seconds.
        #  if this is set to false, then the cb-event-forwarder will not initiate a connection to the remote service unless
        #  there are events to send.
        # upload_empty_files=true

        # Set the maximum file size before the events must be flushed to the remote service. The default is 10MB.
        # bundle_size_max=10485760
        #HEC TOKEN
        #
        #hec_token stores the HEC token to be used when communicating with splunk
        #
        hec_token: PASSWORD


        #CbR Ef 4.0 supports event filtering and custom encoding using golang's
        # text/template package / templating language
        # Filter templates  must return DROP or KEEP strings
        # User can define filters that operate on the keys/values in the in-flight CBEventMessage
        filter:
            enabled: true
            template: >-
                        {{$cbmsg := .}}
                        {{if eq $cbmsg.type "binary.alert"}}
                            KEEP
                        {{- else -}}
                            DROP
                        {{- end -}}
        #
        # This example filter drops any incoming message with/o key.key = literal v
        #
        #encoders format messages . is an in-flight Cb Event Msg - a mapping of string keys to their values
        # This encoder uses an (optional) plugin to Get the currentTime as well as format leef output
        encoder:
            template: "{{LeefFormat .}}{{GetCurrentTimeRFC3339}}"
            plugin: basic_encoder
        #
